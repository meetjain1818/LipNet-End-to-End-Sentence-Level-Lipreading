{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf1ece22-b52e-440b-b9f5-e702e54eedb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.init as init\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import List, Tuple, Optional\n",
    "import imageio\n",
    "import dlib\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import cv2\n",
    "import time\n",
    "import random\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-dark-palette') # Use a compatible style\n",
    "plt.rcParams[\"figure.figsize\"] = (9, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63956a29-bc4d-4178-85eb-cfecf0cf6d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# --- Configuration ---\n",
    "SEED = 6543\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d9ff14b-bfef-4f0c-9378-307c9d7902cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAME_COUNT = 75\n",
    "FRAME_HEIGHT = 50\n",
    "FRAME_WIDTH = 100\n",
    "FRAME_CHANNELS = 3\n",
    "DROPOUT_P = 0.5\n",
    "\n",
    "BASE_PROCESSED_PATH = './GRIDCorpus/processed_mouth_data/'\n",
    "BASE_ALIGN_PATH = './GRIDCorpus/data/'\n",
    "\n",
    "# ALL_SPEAKER_IDS = [f's{i}' for i in range(1, 2) if i != 21]\n",
    "ALL_SPEAKER_IDS = [\"s23_processed\", \"s24_processed\", \"s25_processed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72549801-190e-4f2f-b05a-d65f533e208a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST_SPEAKERS_UNSEEN = ['s1', 's2', 's20', 's22']\n",
    "NUM_TEST_SENTENCES_OVERLAPPED = 200 \n",
    "SPLIT_MODE = 'overlapped' # Choose 'unseen' or 'overlapped'\n",
    "\n",
    "# Normalization constants\n",
    "NORM_MEAN = np.array([0.7136, 0.4906, 0.3283], dtype=np.float32)\n",
    "NORM_STD = np.array([0.1138, 0.1078, 0.0917], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2513c15e-8248-48ef-8868-76f8d5b76333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vocabulary is: ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', ' '] (size =27)\n",
      "CTC Blank Index: 0\n",
      "Label Padding Value: 0\n"
     ]
    }
   ],
   "source": [
    "# --- Vocabulary ---\n",
    "vocab = [x for x in \"abcdefghijklmnopqrstuvwxyz \"]\n",
    "char_to_num_dict = {char: i + 1 for i, char in enumerate(vocab)} # Start indices from 1\n",
    "num_to_char_dict = {i + 1: char for i, char in enumerate(vocab)}\n",
    "VOCAB_SIZE = len(vocab)\n",
    "CTC_BLANK_INDEX = 0 # CTC blank is often index 0 by convention in PyTorch\n",
    "LABEL_PADDING_VALUE = CTC_BLANK_INDEX\n",
    "\n",
    "print(\n",
    "    f\"The vocabulary is: {vocab} \"\n",
    "    f\"(size ={VOCAB_SIZE})\"\n",
    ")\n",
    "print(f\"CTC Blank Index: {CTC_BLANK_INDEX}\")\n",
    "print(f\"Label Padding Value: {LABEL_PADDING_VALUE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8424bde4-0652-4476-a445-3757e6e72fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_alignments(align_file: str) -> Optional[List[str]]:\n",
    "    alignments_chars = []\n",
    "    try:\n",
    "        with open(align_file, 'r') as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) != 3:\n",
    "                    continue\n",
    "                _, _, token = parts\n",
    "                if token != 'sil':\n",
    "                    token_characters = list(token.lower() + ' ')\n",
    "                    alignments_chars.extend(token_characters)\n",
    "        return alignments_chars[:-1] if alignments_chars else []\n",
    "    except FileNotFoundError:\n",
    "         print(f\"Warning: Alignment file not found: {align_file}\")\n",
    "         return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading alignments {align_file}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b14035da-9807-462e-9066-c4aca1bb0e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['l', 'a', 'y', ' ', 'r', 'e', 'd', ' ', 'w', 'i', 't', 'h', ' ', 'z', ' ', 'f', 'o', 'u', 'r', ' ', 'p', 'l', 'e', 'a', 's', 'e']\n"
     ]
    }
   ],
   "source": [
    "example_alignment = load_alignments(\"./GRIDCorpus/data/s1_processed/align/lrwz4p.align\")\n",
    "print(example_alignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "338b18fd-fec0-4a19-99ce-7fdbd8eb4e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using overlapped speakers split. 200 test sentences per speaker.\n",
      "Total files found: 3000\n",
      "Training files: 2400\n",
      "Test files: 600\n"
     ]
    }
   ],
   "source": [
    "# --- File Listing and Splitting ---\n",
    "all_npy_files = []\n",
    "for speaker_id in ALL_SPEAKER_IDS:\n",
    "    speaker_path = os.path.join(BASE_PROCESSED_PATH, speaker_id, '*.npy')\n",
    "    files = glob.glob(speaker_path)\n",
    "    if not files:\n",
    "        print(f\"Warning: No .npy files found for speaker {speaker_id} in {os.path.join(BASE_PROCESSED_PATH, speaker_id)}\")\n",
    "    all_npy_files.extend(files)\n",
    "\n",
    "if not all_npy_files:\n",
    "    raise FileNotFoundError(f\"No .npy files found in {BASE_PROCESSED_PATH} for speakers {ALL_SPEAKER_IDS}. Did preprocessing run?\")\n",
    "\n",
    "np.random.shuffle(all_npy_files)\n",
    "train_files, test_files = [], []\n",
    "\n",
    "if SPLIT_MODE == 'unseen':\n",
    "    print(f\"Using unseen speakers split. Test speakers: {TEST_SPEAKERS_UNSEEN}\")\n",
    "    for f in all_npy_files:\n",
    "        speaker_id = os.path.basename(os.path.dirname(f))\n",
    "        if speaker_id in TEST_SPEAKERS_UNSEEN:\n",
    "            test_files.append(f)\n",
    "        else:\n",
    "            train_files.append(f)\n",
    "elif SPLIT_MODE == 'overlapped':\n",
    "    print(f\"Using overlapped speakers split. {NUM_TEST_SENTENCES_OVERLAPPED} test sentences per speaker.\")\n",
    "    files_by_speaker = {}\n",
    "    for f in all_npy_files:\n",
    "        speaker_id = os.path.basename(os.path.dirname(f))\n",
    "        if speaker_id not in files_by_speaker:\n",
    "            files_by_speaker[speaker_id] = []\n",
    "        files_by_speaker[speaker_id].append(f)\n",
    "\n",
    "    for speaker_id, files in files_by_speaker.items():\n",
    "        np.random.shuffle(files)\n",
    "        test_count = min(NUM_TEST_SENTENCES_OVERLAPPED, len(files))\n",
    "        test_files.extend(files[:test_count])\n",
    "        train_files.extend(files[test_count:])\n",
    "else:\n",
    "    raise ValueError(\"Invalid SPLIT_MODE. Choose 'unseen' or 'overlapped'.\")\n",
    "\n",
    "print(f\"Total files found: {len(all_npy_files)}\")\n",
    "print(f\"Training files: {len(train_files)}\")\n",
    "print(f\"Test files: {len(test_files)}\")\n",
    "\n",
    "if not train_files or not test_files:\n",
    "    raise ValueError(\"Training or test set is empty. Check file paths and splitting logic.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "834ccdb7-5ff3-44e1-a7d0-b3411f81f4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRIDDataset(Dataset):\n",
    "    def __init__(self, file_paths: List[str], augment: bool = True):\n",
    "        self.file_paths = file_paths\n",
    "        self.augment = augment\n",
    "        self.target_frame_count = FRAME_COUNT # Define target length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        npy_path = self.file_paths[idx]\n",
    "        try:\n",
    "            frames_uint8 = np.load(npy_path)\n",
    "\n",
    "            if frames_uint8.ndim != 4 or frames_uint8.shape[1:] != (FRAME_HEIGHT, FRAME_WIDTH, FRAME_CHANNELS):\n",
    "                 print(f\"Warning: Unexpected shape {frames_uint8.shape} for {npy_path}. Skipping.\")\n",
    "                 return torch.zeros((FRAME_COUNT, FRAME_HEIGHT, FRAME_WIDTH, FRAME_CHANNELS), dtype=torch.float32), \\\n",
    "                        torch.tensor([], dtype=torch.long)\n",
    "\n",
    "            current_frame_count = frames_uint8.shape[0]\n",
    "            if current_frame_count != self.target_frame_count:\n",
    "                if current_frame_count > self.target_frame_count:\n",
    "                    frames_uint8 = frames_uint8[:self.target_frame_count, ...]\n",
    "                else:\n",
    "                    pad_width = ((0, self.target_frame_count - current_frame_count), (0, 0), (0, 0), (0, 0))\n",
    "                    frames_uint8 = np.pad(frames_uint8, pad_width, mode='constant', constant_values=0)\n",
    "\n",
    "            frames_float = frames_uint8.astype(np.float32) / 255.0\n",
    "            frames_rgb = frames_float[..., ::-1] # BGR to RGB\n",
    "            frames_normalized = (frames_rgb - NORM_MEAN) / NORM_STD\n",
    "            frames_tensor = torch.tensor(frames_normalized, dtype=torch.float32)\n",
    "            # Shape should now be guaranteed [75, 50, 100, 3]\n",
    "\n",
    "            # getting alignments\n",
    "            parts = npy_path.split(os.path.sep)\n",
    "            speaker_id = parts[-2]\n",
    "            base_name = os.path.splitext(parts[-1])[0]\n",
    "            if base_name.endswith('_mouth'):\n",
    "                base_name = base_name[:-6]\n",
    "            align_file = os.path.join(BASE_ALIGN_PATH, speaker_id, \"align\", f'{base_name}.align')\n",
    "            alignments_list = load_alignments(align_file)\n",
    "\n",
    "            if alignments_list is None:\n",
    "                print(f\"Skipping {npy_path} due to missing alignment.\")\n",
    "                return torch.zeros((FRAME_COUNT, FRAME_HEIGHT, FRAME_WIDTH, FRAME_CHANNELS), dtype=torch.float32), \\\n",
    "                       torch.tensor([], dtype=torch.long)\n",
    "\n",
    "            label_indices = [char_to_num_dict.get(char, CTC_BLANK_INDEX) for char in alignments_list] # Use blank for OOV\n",
    "            label_tensor = torch.tensor(label_indices, dtype=torch.long)\n",
    "\n",
    "            if self.augment and torch.rand(1).item() > 0.5:\n",
    "                frames_tensor = torch.flip(frames_tensor, dims=[2]) # Flip width dimension\n",
    "\n",
    "            return frames_tensor, label_tensor\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Warning: File not found {npy_path}. Skipping.\")\n",
    "            return torch.zeros((FRAME_COUNT, FRAME_HEIGHT, FRAME_WIDTH, FRAME_CHANNELS), dtype=torch.float32), \\\n",
    "                   torch.tensor([], dtype=torch.long)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading item {idx} ({npy_path}): {e}\")\n",
    "            return torch.zeros((FRAME_COUNT, FRAME_HEIGHT, FRAME_WIDTH, FRAME_CHANNELS), dtype=torch.float32), \\\n",
    "                   torch.tensor([], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1976c66-cadc-42de-aadb-631fc8504b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    batch = [(frames, labels) for frames, labels in batch if labels.numel() > 0]\n",
    "    if not batch:\n",
    "        return torch.tensor([]), torch.tensor([]), torch.tensor([]), torch.tensor([])\n",
    "    frames_list, labels_list = zip(*batch)\n",
    "    frames_batch = torch.stack(frames_list, dim=0)\n",
    "    label_lengths = torch.tensor([len(lbl) for lbl in labels_list], dtype=torch.long)\n",
    "    labels_padded = pad_sequence(labels_list, batch_first=True, padding_value=LABEL_PADDING_VALUE)\n",
    "    input_lengths = torch.full(size=(len(batch),), fill_value=FRAME_COUNT, dtype=torch.long)\n",
    "    return frames_batch, labels_padded, input_lengths, label_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5965b310-b0b2-4ce7-b6c0-cff303debedc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GRIDDataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m BATCH_SIZE_TRAIN = \u001b[32m32\u001b[39m\n\u001b[32m      3\u001b[39m BATCH_SIZE_TEST = \u001b[32m32\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m train_dataset = \u001b[43mGRIDDataset\u001b[49m(train_files, augment=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      6\u001b[39m test_dataset = GRIDDataset(test_files, augment=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m      8\u001b[39m train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE_TRAIN, shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m      9\u001b[39m                           collate_fn=collate_fn, num_workers=\u001b[32m4\u001b[39m, pin_memory=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mNameError\u001b[39m: name 'GRIDDataset' is not defined"
     ]
    }
   ],
   "source": [
    "# --- Data Loaders ---\n",
    "BATCH_SIZE_TRAIN = 32\n",
    "BATCH_SIZE_TEST = 32\n",
    "\n",
    "train_dataset = GRIDDataset(train_files, augment=True)\n",
    "test_dataset = GRIDDataset(test_files, augment=False)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE_TRAIN, shuffle=True,\n",
    "                          collate_fn=collate_fn, num_workers=4, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE_TEST, shuffle=False,\n",
    "                         collate_fn=collate_fn, num_workers=4, pin_memory=True)\n",
    "\n",
    "print(\"DataLoaders created.\")\n",
    "# Test one batch\n",
    "try:\n",
    "    d_frames, d_labels, d_in_len, d_lbl_len = next(iter(train_loader))\n",
    "    print(\"Train Batch Shapes:\", d_frames.shape, d_labels.shape, d_in_len.shape, d_lbl_len.shape)\n",
    "    d_frames, d_labels, d_in_len, d_lbl_len = next(iter(test_loader))\n",
    "    print(\"Test Batch Shapes:\", d_frames.shape, d_labels.shape, d_in_len.shape, d_lbl_len.shape)\n",
    "except Exception as e:\n",
    "     print(f\"Error fetching batch: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "984a9fb3-c55e-4c55-af41-0d143b559140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PyTorch LipNet Model ---\n",
    "class LipNet(nn.Module):\n",
    "    def __init__(self, num_classes, dropout_p=DROPOUT_P):\n",
    "        super(LipNet, self).__init__()\n",
    "        self.num_classes = num_classes # Should include blank token\n",
    "        self.dropout_p = dropout_p\n",
    "\n",
    "        # Spatiotemporal Convolutional Layers (STCNN)\n",
    "        self.conv1 = nn.Conv3d(FRAME_CHANNELS, 32, kernel_size=(3, 5, 5), stride=(1, 2, 2), padding=(1, 2, 2))\n",
    "        self.bn1 = nn.BatchNorm3d(32)\n",
    "        self.pool1 = nn.MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2))\n",
    "        self.drop1 = nn.Dropout3d(dropout_p)\n",
    "\n",
    "        self.conv2 = nn.Conv3d(32, 64, kernel_size=(3, 5, 5), stride=(1, 1, 1), padding=(1, 2, 2))\n",
    "        self.bn2 = nn.BatchNorm3d(64)\n",
    "        self.pool2 = nn.MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2))\n",
    "        self.drop2 = nn.Dropout3d(dropout_p)\n",
    "\n",
    "        self.conv3 = nn.Conv3d(64, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
    "        self.bn3 = nn.BatchNorm3d(96)\n",
    "        self.pool3 = nn.MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2))\n",
    "        self.drop3 = nn.Dropout3d(dropout_p)\n",
    "        self.rnn_input_size = 96 * 3 * 6 # C_out * H_out * W_out\n",
    "\n",
    "        # Bidirectional GRU Layers\n",
    "        self.gru1 = nn.GRU(self.rnn_input_size, 256, bidirectional=True, batch_first=True)\n",
    "        self.drop_gru1 = nn.Dropout(dropout_p)\n",
    "        self.gru2 = nn.GRU(256 * 2, 256, bidirectional=True, batch_first=True) # Input size is doubled from previous BiGRU\n",
    "        self.drop_gru2 = nn.Dropout(dropout_p)\n",
    "\n",
    "        # Fully Connected Layer\n",
    "        self.fc = nn.Linear(256 * 2, self.num_classes)\n",
    "\n",
    "        #Initialize weights\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv3d):\n",
    "                init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm3d):\n",
    "                init.constant_(m.weight, 1)\n",
    "                init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.GRU):\n",
    "                for name, param in m.named_parameters():\n",
    "                    if 'weight_ih' in name: # Input-hidden weights\n",
    "                        init.xavier_uniform_(param.data)\n",
    "                    elif 'weight_hh' in name: # Hidden-hidden weights\n",
    "                        init.orthogonal_(param.data)\n",
    "                    elif 'bias' in name: # Biases\n",
    "                        init.constant_(param.data, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                 init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu') # He for Dense\n",
    "                 if m.bias is not None:\n",
    "                    init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 4, 1, 2, 3).contiguous()\n",
    "\n",
    "        # STCNN blocks\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.drop1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.drop2(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool3(x)\n",
    "        x = self.drop3(x)\n",
    "\n",
    "        N, C, T, H, W = x.size()\n",
    "        x = x.permute(0, 2, 1, 3, 4).contiguous() # (N, T, C, H, W)\n",
    "        x = x.view(N, T, -1) # Flatten C, H, W dims\n",
    "\n",
    "        # Bi-GRU layers\n",
    "        x, _ = self.gru1(x)\n",
    "        x = self.drop_gru1(x)\n",
    "        x, _ = self.gru2(x)\n",
    "        x = self.drop_gru2(x)\n",
    "\n",
    "        # Fully Connected Layer\n",
    "        x = self.fc(x) # Output shape: (N, T, num_classes)\n",
    "\n",
    "        # Prepare for CTC Loss: (T, N, C) and apply log_softmax\n",
    "        x = x.permute(1, 0, 2).contiguous() # T, N, C\n",
    "        log_probs = F.log_softmax(x, dim=2)\n",
    "\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d8ccaaf-2b16-44e5-b40f-1a4a1d4b3dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "LipNet                                   [75, 32, 28]              --\n",
      "├─Conv3d: 1-1                            [32, 32, 75, 25, 50]      7,232\n",
      "├─BatchNorm3d: 1-2                       [32, 32, 75, 25, 50]      64\n",
      "├─MaxPool3d: 1-3                         [32, 32, 75, 12, 25]      --\n",
      "├─Dropout3d: 1-4                         [32, 32, 75, 12, 25]      --\n",
      "├─Conv3d: 1-5                            [32, 64, 75, 12, 25]      153,664\n",
      "├─BatchNorm3d: 1-6                       [32, 64, 75, 12, 25]      128\n",
      "├─MaxPool3d: 1-7                         [32, 64, 75, 6, 12]       --\n",
      "├─Dropout3d: 1-8                         [32, 64, 75, 6, 12]       --\n",
      "├─Conv3d: 1-9                            [32, 96, 75, 6, 12]       165,984\n",
      "├─BatchNorm3d: 1-10                      [32, 96, 75, 6, 12]       192\n",
      "├─MaxPool3d: 1-11                        [32, 96, 75, 3, 6]        --\n",
      "├─Dropout3d: 1-12                        [32, 96, 75, 3, 6]        --\n",
      "├─GRU: 1-13                              [32, 75, 512]             3,050,496\n",
      "├─Dropout: 1-14                          [32, 75, 512]             --\n",
      "├─GRU: 1-15                              [32, 75, 512]             1,182,720\n",
      "├─Dropout: 1-16                          [32, 75, 512]             --\n",
      "├─Linear: 1-17                           [32, 75, 28]              14,364\n",
      "==========================================================================================\n",
      "Total params: 4,574,844\n",
      "Trainable params: 4,574,844\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.GIGABYTES): 171.18\n",
      "==========================================================================================\n",
      "Input size (MB): 144.00\n",
      "Forward/backward pass size (MB): 2558.90\n",
      "Params size (MB): 18.30\n",
      "Estimated Total Size (MB): 2721.20\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "model = LipNet(num_classes=VOCAB_SIZE + 1).to(DEVICE) # +1 for blank\n",
    "\n",
    "try:\n",
    "    from torchinfo import summary\n",
    "    print(summary(model, input_size=(BATCH_SIZE_TRAIN, FRAME_COUNT, FRAME_HEIGHT, FRAME_WIDTH, FRAME_CHANNELS)))\n",
    "except ImportError:\n",
    "    print(\"torchinfo not installed. Skipping model summary.\")\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "884339bd-d7d2-4b0f-9a4f-7a1e8eaad87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Loss Function ---\n",
    "ctc_loss = nn.CTCLoss(blank=CTC_BLANK_INDEX, reduction='mean', zero_infinity=True)\n",
    "\n",
    "# --- Optimizer ---\n",
    "LEARNING_RATE = 1e-4\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay = 1e-4)\n",
    "\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.2, patience=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "723e00e2-f449-4abb-b93d-a296fe8da20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Checkpoint Path ---\n",
    "checkpoint_dir = 'models_pytorch'\n",
    "checkpoint_path = os.path.join(checkpoint_dir, 'lipnet_checkpoint.pth')\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c134986-8e30-41cb-a21d-11974017a273",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decoder(log_probs, input_lengths):\n",
    "    decoded_sequences = []\n",
    "    for i in range(log_probs.size(1)): \n",
    "        sample_log_probs = log_probs[:input_lengths[i], i, :]\n",
    "        best_path = torch.argmax(sample_log_probs, dim=1)\n",
    "        decoded = []\n",
    "        last_char = -1\n",
    "        for char_idx in best_path:\n",
    "            idx = char_idx.item()\n",
    "            if idx != last_char and idx != CTC_BLANK_INDEX:\n",
    "                decoded.append(idx)\n",
    "            if idx != CTC_BLANK_INDEX: \n",
    "                last_char = idx\n",
    "        decoded_sequences.append(decoded)\n",
    "    return decoded_sequences\n",
    "def produce_example(model, dataset_loader, num_to_char_map):\n",
    "    model.eval() \n",
    "    with torch.no_grad():\n",
    "        try:\n",
    "            frames_batch, labels_batch, input_lengths, label_lengths = next(iter(dataset_loader))\n",
    "            frames_batch = frames_batch.to(DEVICE)\n",
    "            log_probs = model(frames_batch) \n",
    "            log_probs_cpu = log_probs.cpu()\n",
    "            raw_argmax = torch.argmax(log_probs_cpu[:, 0, :], dim=1) \n",
    "            print(f\"Raw Argmax Indices (Example 1): {raw_argmax.tolist()}\")\n",
    "            input_lengths_cpu = input_lengths.cpu()\n",
    "            decoded_indices_list = greedy_decoder(log_probs_cpu, input_lengths_cpu)\n",
    "            print(\"\\n--- Example Predictions ---\")\n",
    "            N_EXAMPLES_TO_SHOW = min(2, frames_batch.size(0))\n",
    "            for i in range(N_EXAMPLES_TO_SHOW):\n",
    "                original_indices = labels_batch[i][:label_lengths[i]].tolist()\n",
    "                original_text = \"\".join([num_to_char_map.get(idx, '?') for idx in original_indices])\n",
    "                print(f'Original:     {original_text}')\n",
    "                prediction_indices = decoded_indices_list[i]\n",
    "                print(f'Filtered Idx: {prediction_indices}') \n",
    "                prediction_text = \"\".join([num_to_char_map.get(idx, '?') for idx in prediction_indices])\n",
    "                print(f'Prediction:   {prediction_text}')\n",
    "                print('-'*50)\n",
    "            print(\"--- End Examples ---\\n\")\n",
    "        except StopIteration:\n",
    "            print(\"Warning: Could not get a batch from the dataset loader for ProduceExample.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error during ProduceExample: {e}\")\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e1edb1f6-c6be-4826-a7f8-2f2cc37043e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint from models_pytorch/lipnet_checkpoint.pth\n",
      "Resuming training from epoch 200, Best loss: 1.6684\n",
      "\n",
      "Starting Training...\n",
      "Training batches per epoch: 75\n",
      "Validation batches per epoch: 19\n",
      "\n",
      "Epoch 201/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 201 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.77]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 201 Training Loss: 1.7676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 201 Val: 100%|██████████| 19/19 [00:04<00:00,  3.99it/s, val_loss=1.68]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 201 Validation Loss: 1.6841\n",
      "Validation loss (1.6841) did not improve from 1.6684\n",
      "\n",
      "Epoch 202/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 202 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.77]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 202 Training Loss: 1.7685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 202 Val: 100%|██████████| 19/19 [00:04<00:00,  3.93it/s, val_loss=1.69]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 202 Validation Loss: 1.6896\n",
      "Validation loss (1.6896) did not improve from 1.6684\n",
      "\n",
      "Epoch 203/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 203 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.76]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 203 Training Loss: 1.7643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 203 Val: 100%|██████████| 19/19 [00:04<00:00,  3.94it/s, val_loss=1.67]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 203 Validation Loss: 1.6727\n",
      "Validation loss (1.6727) did not improve from 1.6684\n",
      "\n",
      "Epoch 204/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 204 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.76]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 204 Training Loss: 1.7617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 204 Val: 100%|██████████| 19/19 [00:04<00:00,  4.00it/s, val_loss=1.68]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 204 Validation Loss: 1.6799\n",
      "Validation loss (1.6799) did not improve from 1.6684\n",
      "\n",
      "Epoch 205/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 205 Train: 100%|██████████| 75/75 [00:45<00:00,  1.64it/s, loss=1.76]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 205 Training Loss: 1.7607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 205 Val: 100%|██████████| 19/19 [00:04<00:00,  3.89it/s, val_loss=1.67]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 205 Validation Loss: 1.6739\n",
      "Validation loss (1.6739) did not improve from 1.6684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Argmax Indices (Example 1): [19, 0, 1, 20, 27, 27, 23, 18, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 20, 27, 27, 27, 27, 27, 27, 27, 27, 27, 9, 9, 5, 0, 0, 27, 27, 0, 0, 0, 1, 15, 14]\n",
      "\n",
      "--- Example Predictions ---\n",
      "Original:     set blue with f four now\n",
      "Filtered Idx: [19, 1, 20, 27, 23, 18, 5, 9, 20, 27, 9, 5, 27, 1, 15, 14]\n",
      "Prediction:   sat wreit ie aon\n",
      "--------------------------------------------------\n",
      "Original:     set white in m one again\n",
      "Filtered Idx: [19, 1, 25, 27, 23, 18, 9, 20, 27, 9, 5, 27, 15, 14]\n",
      "Prediction:   say writ ie on\n",
      "--------------------------------------------------\n",
      "--- End Examples ---\n",
      "\n",
      "\n",
      "Epoch 206/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 206 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.76]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 206 Training Loss: 1.7613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 206 Val: 100%|██████████| 19/19 [00:04<00:00,  4.07it/s, val_loss=1.67]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 206 Validation Loss: 1.6747\n",
      "Validation loss (1.6747) did not improve from 1.6684\n",
      "\n",
      "Epoch 207/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 207 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.75]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 207 Training Loss: 1.7543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 207 Val: 100%|██████████| 19/19 [00:04<00:00,  4.07it/s, val_loss=1.66]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 207 Validation Loss: 1.6604\n",
      "Validation loss improved from 1.6684 to 1.6604, saving model to models_pytorch/lipnet_checkpoint.pth\n",
      "\n",
      "Epoch 208/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 208 Train: 100%|██████████| 75/75 [00:45<00:00,  1.64it/s, loss=1.76]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 208 Training Loss: 1.7570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 208 Val: 100%|██████████| 19/19 [00:04<00:00,  4.05it/s, val_loss=1.66]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 208 Validation Loss: 1.6633\n",
      "Validation loss (1.6633) did not improve from 1.6604\n",
      "\n",
      "Epoch 209/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 209 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.76]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 209 Training Loss: 1.7556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 209 Val: 100%|██████████| 19/19 [00:04<00:00,  4.04it/s, val_loss=1.67]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 209 Validation Loss: 1.6673\n",
      "Validation loss (1.6673) did not improve from 1.6604\n",
      "\n",
      "Epoch 210/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 210 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.76]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 210 Training Loss: 1.7552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 210 Val: 100%|██████████| 19/19 [00:04<00:00,  4.04it/s, val_loss=1.63]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 210 Validation Loss: 1.6341\n",
      "Validation loss improved from 1.6604 to 1.6341, saving model to models_pytorch/lipnet_checkpoint.pth\n",
      "Raw Argmax Indices (Example 1): [19, 0, 1, 25, 27, 27, 23, 18, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 20, 27, 27, 27, 27, 27, 27, 27, 27, 27, 9, 9, 5, 0, 0, 27, 27, 0, 0, 0, 0, 15, 14]\n",
      "\n",
      "--- Example Predictions ---\n",
      "Original:     set blue with f four now\n",
      "Filtered Idx: [19, 1, 25, 27, 23, 18, 5, 9, 20, 27, 9, 5, 27, 15, 14]\n",
      "Prediction:   say wreit ie on\n",
      "--------------------------------------------------\n",
      "Original:     set white in m one again\n",
      "Filtered Idx: [19, 1, 25, 27, 23, 18, 5, 9, 20, 27, 9, 5, 27, 1, 15, 14]\n",
      "Prediction:   say wreit ie aon\n",
      "--------------------------------------------------\n",
      "--- End Examples ---\n",
      "\n",
      "\n",
      "Epoch 211/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 211 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.75]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 211 Training Loss: 1.7481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 211 Val: 100%|██████████| 19/19 [00:04<00:00,  3.98it/s, val_loss=1.67]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 211 Validation Loss: 1.6747\n",
      "Validation loss (1.6747) did not improve from 1.6341\n",
      "\n",
      "Epoch 212/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 212 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.75]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 212 Training Loss: 1.7473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 212 Val: 100%|██████████| 19/19 [00:04<00:00,  3.85it/s, val_loss=1.65]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 212 Validation Loss: 1.6511\n",
      "Validation loss (1.6511) did not improve from 1.6341\n",
      "\n",
      "Epoch 213/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 213 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.75]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 213 Training Loss: 1.7451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 213 Val: 100%|██████████| 19/19 [00:05<00:00,  3.78it/s, val_loss=1.64]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 213 Validation Loss: 1.6431\n",
      "Validation loss (1.6431) did not improve from 1.6341\n",
      "\n",
      "Epoch 214/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 214 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.75]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 214 Training Loss: 1.7461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 214 Val: 100%|██████████| 19/19 [00:04<00:00,  3.96it/s, val_loss=1.64]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 214 Validation Loss: 1.6366\n",
      "Validation loss (1.6366) did not improve from 1.6341\n",
      "\n",
      "Epoch 215/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 215 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.74]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 215 Training Loss: 1.7429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 215 Val: 100%|██████████| 19/19 [00:04<00:00,  3.95it/s, val_loss=1.65]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 215 Validation Loss: 1.6544\n",
      "Validation loss (1.6544) did not improve from 1.6341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Argmax Indices (Example 1): [19, 0, 1, 20, 27, 27, 23, 18, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 20, 27, 27, 27, 27, 27, 27, 27, 27, 27, 9, 9, 5, 0, 0, 27, 27, 27, 0, 14, 1, 15, 14]\n",
      "\n",
      "--- Example Predictions ---\n",
      "Original:     set blue with f four now\n",
      "Filtered Idx: [19, 1, 20, 27, 23, 18, 5, 9, 20, 27, 9, 5, 27, 14, 1, 15, 14]\n",
      "Prediction:   sat wreit ie naon\n",
      "--------------------------------------------------\n",
      "Original:     set white in m one again\n",
      "Filtered Idx: [19, 1, 20, 27, 23, 18, 9, 20, 27, 9, 5, 27, 15, 1, 15, 14]\n",
      "Prediction:   sat writ ie oaon\n",
      "--------------------------------------------------\n",
      "--- End Examples ---\n",
      "\n",
      "\n",
      "Epoch 216/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 216 Train: 100%|██████████| 75/75 [00:45<00:00,  1.64it/s, loss=1.74]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 216 Training Loss: 1.7414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 216 Val: 100%|██████████| 19/19 [00:04<00:00,  3.87it/s, val_loss=1.65]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 216 Validation Loss: 1.6454\n",
      "Validation loss (1.6454) did not improve from 1.6341\n",
      "\n",
      "Epoch 217/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 217 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.74]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 217 Training Loss: 1.7384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 217 Val: 100%|██████████| 19/19 [00:05<00:00,  3.77it/s, val_loss=1.64]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 217 Validation Loss: 1.6362\n",
      "Validation loss (1.6362) did not improve from 1.6341\n",
      "\n",
      "Epoch 218/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 218 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.74]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 218 Training Loss: 1.7382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 218 Val: 100%|██████████| 19/19 [00:04<00:00,  3.83it/s, val_loss=1.64]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 218 Validation Loss: 1.6358\n",
      "Validation loss (1.6358) did not improve from 1.6341\n",
      "\n",
      "Epoch 219/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 219 Train: 100%|██████████| 75/75 [00:45<00:00,  1.64it/s, loss=1.74]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 219 Training Loss: 1.7372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 219 Val: 100%|██████████| 19/19 [00:04<00:00,  3.90it/s, val_loss=1.63]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 219 Validation Loss: 1.6317\n",
      "Validation loss improved from 1.6341 to 1.6317, saving model to models_pytorch/lipnet_checkpoint.pth\n",
      "\n",
      "Epoch 220/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 220 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.74]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 220 Training Loss: 1.7361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 220 Val: 100%|██████████| 19/19 [00:04<00:00,  4.05it/s, val_loss=1.63]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 220 Validation Loss: 1.6267\n",
      "Validation loss improved from 1.6317 to 1.6267, saving model to models_pytorch/lipnet_checkpoint.pth\n",
      "Raw Argmax Indices (Example 1): [19, 0, 1, 20, 27, 27, 23, 18, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 20, 27, 27, 27, 27, 27, 27, 27, 27, 27, 19, 9, 5, 0, 0, 27, 27, 27, 0, 14, 1, 15, 14]\n",
      "\n",
      "--- Example Predictions ---\n",
      "Original:     set blue with f four now\n",
      "Filtered Idx: [19, 1, 20, 27, 23, 18, 5, 9, 20, 27, 19, 9, 5, 27, 14, 1, 15, 14]\n",
      "Prediction:   sat wreit sie naon\n",
      "--------------------------------------------------\n",
      "Original:     set white in m one again\n",
      "Filtered Idx: [19, 1, 25, 27, 23, 18, 5, 9, 20, 27, 9, 5, 27, 15, 1, 15, 14]\n",
      "Prediction:   say wreit ie oaon\n",
      "--------------------------------------------------\n",
      "--- End Examples ---\n",
      "\n",
      "\n",
      "Epoch 221/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 221 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.74]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 221 Training Loss: 1.7352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 221 Val: 100%|██████████| 19/19 [00:04<00:00,  3.84it/s, val_loss=1.63]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 221 Validation Loss: 1.6260\n",
      "Validation loss improved from 1.6267 to 1.6260, saving model to models_pytorch/lipnet_checkpoint.pth\n",
      "\n",
      "Epoch 222/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 222 Train: 100%|██████████| 75/75 [00:45<00:00,  1.64it/s, loss=1.73]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 222 Training Loss: 1.7327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 222 Val: 100%|██████████| 19/19 [00:04<00:00,  4.05it/s, val_loss=1.63]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 222 Validation Loss: 1.6260\n",
      "Validation loss improved from 1.6260 to 1.6260, saving model to models_pytorch/lipnet_checkpoint.pth\n",
      "\n",
      "Epoch 223/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 223 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.73]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 223 Training Loss: 1.7311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 223 Val: 100%|██████████| 19/19 [00:04<00:00,  3.85it/s, val_loss=1.63]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 223 Validation Loss: 1.6267\n",
      "Validation loss (1.6267) did not improve from 1.6260\n",
      "\n",
      "Epoch 224/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 224 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.73]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 224 Training Loss: 1.7342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 224 Val: 100%|██████████| 19/19 [00:04<00:00,  3.99it/s, val_loss=1.63]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 224 Validation Loss: 1.6287\n",
      "Validation loss (1.6287) did not improve from 1.6260\n",
      "\n",
      "Epoch 225/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 225 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.73]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225 Training Loss: 1.7348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 225 Val: 100%|██████████| 19/19 [00:04<00:00,  3.85it/s, val_loss=1.63]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225 Validation Loss: 1.6262\n",
      "Validation loss (1.6262) did not improve from 1.6260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Argmax Indices (Example 1): [19, 0, 1, 20, 27, 27, 7, 18, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 20, 27, 27, 27, 27, 27, 27, 27, 27, 27, 9, 9, 5, 0, 0, 27, 27, 27, 0, 14, 1, 15, 14]\n",
      "\n",
      "--- Example Predictions ---\n",
      "Original:     set blue with f four now\n",
      "Filtered Idx: [19, 1, 20, 27, 7, 18, 5, 9, 20, 27, 9, 5, 27, 14, 1, 15, 14]\n",
      "Prediction:   sat greit ie naon\n",
      "--------------------------------------------------\n",
      "Original:     set white in m one again\n",
      "Filtered Idx: [19, 1, 25, 27, 23, 18, 5, 9, 20, 27, 9, 5, 27, 15, 1, 15, 14]\n",
      "Prediction:   say wreit ie oaon\n",
      "--------------------------------------------------\n",
      "--- End Examples ---\n",
      "\n",
      "\n",
      "Epoch 226/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 226 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.73]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 226 Training Loss: 1.7339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 226 Val: 100%|██████████| 19/19 [00:04<00:00,  3.91it/s, val_loss=1.63]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 226 Validation Loss: 1.6252\n",
      "Validation loss improved from 1.6260 to 1.6252, saving model to models_pytorch/lipnet_checkpoint.pth\n",
      "\n",
      "Epoch 227/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 227 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.73]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 227 Training Loss: 1.7346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 227 Val: 100%|██████████| 19/19 [00:04<00:00,  3.99it/s, val_loss=1.62]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 227 Validation Loss: 1.6246\n",
      "Validation loss improved from 1.6252 to 1.6246, saving model to models_pytorch/lipnet_checkpoint.pth\n",
      "\n",
      "Epoch 228/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 228 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.73]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 228 Training Loss: 1.7310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 228 Val: 100%|██████████| 19/19 [00:04<00:00,  3.91it/s, val_loss=1.63]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 228 Validation Loss: 1.6278\n",
      "Validation loss (1.6278) did not improve from 1.6246\n",
      "\n",
      "Epoch 229/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 229 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.73]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229 Training Loss: 1.7292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 229 Val: 100%|██████████| 19/19 [00:04<00:00,  4.04it/s, val_loss=1.62]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229 Validation Loss: 1.6218\n",
      "Validation loss improved from 1.6246 to 1.6218, saving model to models_pytorch/lipnet_checkpoint.pth\n",
      "\n",
      "Epoch 230/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 230 Train: 100%|██████████| 75/75 [00:45<00:00,  1.64it/s, loss=1.73]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230 Training Loss: 1.7308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 230 Val: 100%|██████████| 19/19 [00:04<00:00,  4.00it/s, val_loss=1.62]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230 Validation Loss: 1.6211\n",
      "Validation loss improved from 1.6218 to 1.6211, saving model to models_pytorch/lipnet_checkpoint.pth\n",
      "Raw Argmax Indices (Example 1): [19, 0, 1, 20, 27, 27, 7, 18, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 20, 27, 27, 27, 27, 27, 27, 27, 27, 27, 9, 9, 5, 0, 0, 27, 27, 27, 0, 14, 1, 15, 14]\n",
      "\n",
      "--- Example Predictions ---\n",
      "Original:     set blue with f four now\n",
      "Filtered Idx: [19, 1, 20, 27, 7, 18, 5, 9, 20, 27, 9, 5, 27, 14, 1, 15, 14]\n",
      "Prediction:   sat greit ie naon\n",
      "--------------------------------------------------\n",
      "Original:     set white in m one again\n",
      "Filtered Idx: [19, 1, 25, 27, 23, 18, 5, 20, 27, 9, 5, 27, 15, 1, 15, 14]\n",
      "Prediction:   say wret ie oaon\n",
      "--------------------------------------------------\n",
      "--- End Examples ---\n",
      "\n",
      "\n",
      "Epoch 231/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 231 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.73]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 231 Training Loss: 1.7307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 231 Val: 100%|██████████| 19/19 [00:04<00:00,  4.06it/s, val_loss=1.62]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 231 Validation Loss: 1.6214\n",
      "Validation loss (1.6214) did not improve from 1.6211\n",
      "\n",
      "Epoch 232/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 232 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.73]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 232 Training Loss: 1.7314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 232 Val: 100%|██████████| 19/19 [00:04<00:00,  3.94it/s, val_loss=1.62]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 232 Validation Loss: 1.6198\n",
      "Validation loss improved from 1.6211 to 1.6198, saving model to models_pytorch/lipnet_checkpoint.pth\n",
      "\n",
      "Epoch 233/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 233 Train: 100%|██████████| 75/75 [00:45<00:00,  1.64it/s, loss=1.73]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 233 Training Loss: 1.7260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 233 Val: 100%|██████████| 19/19 [00:04<00:00,  4.05it/s, val_loss=1.63]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 233 Validation Loss: 1.6277\n",
      "Validation loss (1.6277) did not improve from 1.6198\n",
      "\n",
      "Epoch 234/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 234 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.73]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 234 Training Loss: 1.7306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 234 Val: 100%|██████████| 19/19 [00:04<00:00,  3.85it/s, val_loss=1.63]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 234 Validation Loss: 1.6276\n",
      "Validation loss (1.6276) did not improve from 1.6198\n",
      "\n",
      "Epoch 235/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 235 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.73]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 235 Training Loss: 1.7322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 235 Val: 100%|██████████| 19/19 [00:04<00:00,  3.84it/s, val_loss=1.62]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 235 Validation Loss: 1.6206\n",
      "Validation loss (1.6206) did not improve from 1.6198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Argmax Indices (Example 1): [19, 0, 1, 20, 27, 27, 7, 18, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 20, 27, 27, 27, 27, 27, 27, 27, 27, 27, 19, 9, 5, 0, 0, 27, 27, 27, 0, 14, 1, 15, 14]\n",
      "\n",
      "--- Example Predictions ---\n",
      "Original:     set blue with f four now\n",
      "Filtered Idx: [19, 1, 20, 27, 7, 18, 5, 9, 20, 27, 19, 9, 5, 27, 14, 1, 15, 14]\n",
      "Prediction:   sat greit sie naon\n",
      "--------------------------------------------------\n",
      "Original:     set white in m one again\n",
      "Filtered Idx: [19, 1, 25, 27, 23, 18, 5, 20, 27, 9, 5, 27, 15, 1, 15, 14]\n",
      "Prediction:   say wret ie oaon\n",
      "--------------------------------------------------\n",
      "--- End Examples ---\n",
      "\n",
      "\n",
      "Epoch 236/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 236 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.73]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 236 Training Loss: 1.7272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 236 Val: 100%|██████████| 19/19 [00:04<00:00,  3.93it/s, val_loss=1.62]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 236 Validation Loss: 1.6202\n",
      "Validation loss (1.6202) did not improve from 1.6198\n",
      "\n",
      "Epoch 237/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 237 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.73]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 237 Training Loss: 1.7261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 237 Val: 100%|██████████| 19/19 [00:04<00:00,  3.94it/s, val_loss=1.62]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 237 Validation Loss: 1.6183\n",
      "Validation loss improved from 1.6198 to 1.6183, saving model to models_pytorch/lipnet_checkpoint.pth\n",
      "\n",
      "Epoch 238/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 238 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.73]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 238 Training Loss: 1.7267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 238 Val: 100%|██████████| 19/19 [00:04<00:00,  3.97it/s, val_loss=1.62]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 238 Validation Loss: 1.6172\n",
      "Validation loss improved from 1.6183 to 1.6172, saving model to models_pytorch/lipnet_checkpoint.pth\n",
      "\n",
      "Epoch 239/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 239 Train: 100%|██████████| 75/75 [00:45<00:00,  1.64it/s, loss=1.73]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239 Training Loss: 1.7286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 239 Val: 100%|██████████| 19/19 [00:04<00:00,  3.99it/s, val_loss=1.62]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239 Validation Loss: 1.6195\n",
      "Validation loss (1.6195) did not improve from 1.6172\n",
      "\n",
      "Epoch 240/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 240 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.73]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 240 Training Loss: 1.7266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 240 Val: 100%|██████████| 19/19 [00:04<00:00,  4.06it/s, val_loss=1.62]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 240 Validation Loss: 1.6153\n",
      "Validation loss improved from 1.6172 to 1.6153, saving model to models_pytorch/lipnet_checkpoint.pth\n",
      "Raw Argmax Indices (Example 1): [19, 0, 1, 20, 27, 27, 7, 18, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 20, 27, 27, 27, 27, 27, 27, 27, 27, 27, 19, 9, 5, 0, 0, 27, 27, 27, 0, 14, 1, 15, 14]\n",
      "\n",
      "--- Example Predictions ---\n",
      "Original:     set blue with f four now\n",
      "Filtered Idx: [19, 1, 20, 27, 7, 18, 5, 9, 20, 27, 19, 9, 5, 27, 14, 1, 15, 14]\n",
      "Prediction:   sat greit sie naon\n",
      "--------------------------------------------------\n",
      "Original:     set white in m one again\n",
      "Filtered Idx: [19, 1, 25, 27, 23, 18, 5, 9, 20, 27, 9, 5, 27, 15, 1, 15, 14]\n",
      "Prediction:   say wreit ie oaon\n",
      "--------------------------------------------------\n",
      "--- End Examples ---\n",
      "\n",
      "\n",
      "Epoch 241/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 241 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.73]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241 Training Loss: 1.7268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 241 Val: 100%|██████████| 19/19 [00:04<00:00,  4.00it/s, val_loss=1.62]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241 Validation Loss: 1.6204\n",
      "Validation loss (1.6204) did not improve from 1.6153\n",
      "\n",
      "Epoch 242/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 242 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.73]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 242 Training Loss: 1.7275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 242 Val: 100%|██████████| 19/19 [00:04<00:00,  3.97it/s, val_loss=1.62]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 242 Validation Loss: 1.6199\n",
      "Validation loss (1.6199) did not improve from 1.6153\n",
      "\n",
      "Epoch 243/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 243 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.73]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 243 Training Loss: 1.7272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 243 Val: 100%|██████████| 19/19 [00:04<00:00,  4.00it/s, val_loss=1.61]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 243 Validation Loss: 1.6127\n",
      "Validation loss improved from 1.6153 to 1.6127, saving model to models_pytorch/lipnet_checkpoint.pth\n",
      "\n",
      "Epoch 244/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 244 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.72]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 244 Training Loss: 1.7199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 244 Val: 100%|██████████| 19/19 [00:04<00:00,  4.05it/s, val_loss=1.62]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 244 Validation Loss: 1.6174\n",
      "Validation loss (1.6174) did not improve from 1.6127\n",
      "\n",
      "Epoch 245/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 245 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.73]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 245 Training Loss: 1.7258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 245 Val: 100%|██████████| 19/19 [00:04<00:00,  3.91it/s, val_loss=1.62]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 245 Validation Loss: 1.6158\n",
      "Validation loss (1.6158) did not improve from 1.6127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Argmax Indices (Example 1): [19, 0, 1, 20, 27, 27, 7, 18, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 20, 27, 27, 27, 27, 27, 27, 27, 27, 27, 19, 9, 5, 0, 0, 27, 27, 27, 0, 14, 1, 15, 14]\n",
      "\n",
      "--- Example Predictions ---\n",
      "Original:     set blue with f four now\n",
      "Filtered Idx: [19, 1, 20, 27, 7, 18, 5, 9, 20, 27, 19, 9, 5, 27, 14, 1, 15, 14]\n",
      "Prediction:   sat greit sie naon\n",
      "--------------------------------------------------\n",
      "Original:     set white in m one again\n",
      "Filtered Idx: [19, 1, 25, 27, 23, 18, 5, 9, 20, 27, 9, 5, 27, 15, 1, 15, 14]\n",
      "Prediction:   say wreit ie oaon\n",
      "--------------------------------------------------\n",
      "--- End Examples ---\n",
      "\n",
      "\n",
      "Epoch 246/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 246 Train: 100%|██████████| 75/75 [00:45<00:00,  1.64it/s, loss=1.72]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 246 Training Loss: 1.7248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 246 Val: 100%|██████████| 19/19 [00:04<00:00,  3.99it/s, val_loss=1.61]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 246 Validation Loss: 1.6141\n",
      "Validation loss (1.6141) did not improve from 1.6127\n",
      "\n",
      "Epoch 247/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 247 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.72]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 247 Training Loss: 1.7242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 247 Val: 100%|██████████| 19/19 [00:05<00:00,  3.79it/s, val_loss=1.61]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 247 Validation Loss: 1.6092\n",
      "Validation loss improved from 1.6127 to 1.6092, saving model to models_pytorch/lipnet_checkpoint.pth\n",
      "\n",
      "Epoch 248/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 248 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.72]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 248 Training Loss: 1.7198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 248 Val: 100%|██████████| 19/19 [00:04<00:00,  3.87it/s, val_loss=1.62]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 248 Validation Loss: 1.6164\n",
      "Validation loss (1.6164) did not improve from 1.6092\n",
      "\n",
      "Epoch 249/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 249 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.72]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249 Training Loss: 1.7223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 249 Val: 100%|██████████| 19/19 [00:04<00:00,  3.86it/s, val_loss=1.61]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249 Validation Loss: 1.6128\n",
      "Validation loss (1.6128) did not improve from 1.6092\n",
      "\n",
      "Epoch 250/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 250 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.72]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 250 Training Loss: 1.7204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 250 Val: 100%|██████████| 19/19 [00:04<00:00,  3.91it/s, val_loss=1.61]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 250 Validation Loss: 1.6054\n",
      "Validation loss improved from 1.6092 to 1.6054, saving model to models_pytorch/lipnet_checkpoint.pth\n",
      "Raw Argmax Indices (Example 1): [19, 0, 1, 20, 27, 27, 7, 18, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 20, 27, 27, 27, 27, 27, 27, 27, 27, 27, 9, 9, 5, 0, 0, 27, 27, 27, 0, 14, 1, 15, 14]\n",
      "\n",
      "--- Example Predictions ---\n",
      "Original:     set blue with f four now\n",
      "Filtered Idx: [19, 1, 20, 27, 7, 18, 5, 9, 20, 27, 9, 5, 27, 14, 1, 15, 14]\n",
      "Prediction:   sat greit ie naon\n",
      "--------------------------------------------------\n",
      "Original:     set white in m one again\n",
      "Filtered Idx: [19, 1, 25, 27, 23, 18, 5, 9, 20, 27, 9, 5, 27, 15, 1, 15, 14]\n",
      "Prediction:   say wreit ie oaon\n",
      "--------------------------------------------------\n",
      "--- End Examples ---\n",
      "\n",
      "\n",
      "Epoch 251/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 251 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.72]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 251 Training Loss: 1.7232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 251 Val: 100%|██████████| 19/19 [00:04<00:00,  4.02it/s, val_loss=1.61]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 251 Validation Loss: 1.6139\n",
      "Validation loss (1.6139) did not improve from 1.6054\n",
      "\n",
      "Epoch 252/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 252 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.72]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 252 Training Loss: 1.7231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 252 Val: 100%|██████████| 19/19 [00:04<00:00,  3.97it/s, val_loss=1.61]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 252 Validation Loss: 1.6077\n",
      "Validation loss (1.6077) did not improve from 1.6054\n",
      "\n",
      "Epoch 253/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 253 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.72]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 253 Training Loss: 1.7209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 253 Val: 100%|██████████| 19/19 [00:04<00:00,  3.89it/s, val_loss=1.61]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 253 Validation Loss: 1.6100\n",
      "Validation loss (1.6100) did not improve from 1.6054\n",
      "\n",
      "Epoch 254/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 254 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.72]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 254 Training Loss: 1.7218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 254 Val: 100%|██████████| 19/19 [00:04<00:00,  3.95it/s, val_loss=1.6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 254 Validation Loss: 1.6028\n",
      "Validation loss improved from 1.6054 to 1.6028, saving model to models_pytorch/lipnet_checkpoint.pth\n",
      "\n",
      "Epoch 255/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 255 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.72]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 255 Training Loss: 1.7205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 255 Val: 100%|██████████| 19/19 [00:04<00:00,  4.01it/s, val_loss=1.6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 255 Validation Loss: 1.6021\n",
      "Validation loss improved from 1.6028 to 1.6021, saving model to models_pytorch/lipnet_checkpoint.pth\n",
      "Raw Argmax Indices (Example 1): [19, 0, 1, 20, 27, 27, 7, 18, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 20, 27, 27, 27, 27, 27, 27, 27, 27, 27, 19, 9, 5, 0, 0, 27, 27, 27, 0, 14, 1, 15, 14]\n",
      "\n",
      "--- Example Predictions ---\n",
      "Original:     set blue with f four now\n",
      "Filtered Idx: [19, 1, 20, 27, 7, 18, 5, 9, 20, 27, 19, 9, 5, 27, 14, 1, 15, 14]\n",
      "Prediction:   sat greit sie naon\n",
      "--------------------------------------------------\n",
      "Original:     set white in m one again\n",
      "Filtered Idx: [19, 1, 25, 27, 23, 18, 5, 9, 20, 27, 9, 5, 27, 15, 1, 15, 14]\n",
      "Prediction:   say wreit ie oaon\n",
      "--------------------------------------------------\n",
      "--- End Examples ---\n",
      "\n",
      "\n",
      "Epoch 256/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 256 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.72]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 256 Training Loss: 1.7206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 256 Val: 100%|██████████| 19/19 [00:04<00:00,  3.83it/s, val_loss=1.61]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 256 Validation Loss: 1.6066\n",
      "Validation loss (1.6066) did not improve from 1.6021\n",
      "\n",
      "Epoch 257/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 257 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.72]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 257 Training Loss: 1.7193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 257 Val: 100%|██████████| 19/19 [00:04<00:00,  3.89it/s, val_loss=1.6] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 257 Validation Loss: 1.6040\n",
      "Validation loss (1.6040) did not improve from 1.6021\n",
      "\n",
      "Epoch 258/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 258 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.72]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 258 Training Loss: 1.7216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 258 Val: 100%|██████████| 19/19 [00:04<00:00,  4.01it/s, val_loss=1.6] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 258 Validation Loss: 1.6029\n",
      "Validation loss (1.6029) did not improve from 1.6021\n",
      "\n",
      "Epoch 259/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 259 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.72]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 259 Training Loss: 1.7205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 259 Val: 100%|██████████| 19/19 [00:04<00:00,  3.91it/s, val_loss=1.6] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 259 Validation Loss: 1.6026\n",
      "Validation loss (1.6026) did not improve from 1.6021\n",
      "\n",
      "Epoch 260/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 260 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.72]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 260 Training Loss: 1.7154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 260 Val: 100%|██████████| 19/19 [00:04<00:00,  4.00it/s, val_loss=1.6] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 260 Validation Loss: 1.6026\n",
      "Validation loss (1.6026) did not improve from 1.6021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Argmax Indices (Example 1): [19, 0, 1, 20, 27, 27, 7, 18, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 20, 27, 27, 27, 27, 27, 27, 27, 27, 27, 19, 9, 5, 0, 0, 27, 27, 27, 0, 14, 1, 15, 14]\n",
      "\n",
      "--- Example Predictions ---\n",
      "Original:     set blue with f four now\n",
      "Filtered Idx: [19, 1, 20, 27, 7, 18, 5, 9, 20, 27, 19, 9, 5, 27, 14, 1, 15, 14]\n",
      "Prediction:   sat greit sie naon\n",
      "--------------------------------------------------\n",
      "Original:     set white in m one again\n",
      "Filtered Idx: [19, 1, 25, 27, 23, 18, 5, 20, 27, 9, 5, 27, 15, 1, 15, 14]\n",
      "Prediction:   say wret ie oaon\n",
      "--------------------------------------------------\n",
      "--- End Examples ---\n",
      "\n",
      "\n",
      "Epoch 261/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 261 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.72]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 261 Training Loss: 1.7176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 261 Val: 100%|██████████| 19/19 [00:04<00:00,  4.04it/s, val_loss=1.6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 261 Validation Loss: 1.5996\n",
      "Validation loss improved from 1.6021 to 1.5996, saving model to models_pytorch/lipnet_checkpoint.pth\n",
      "\n",
      "Epoch 262/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 262 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.71]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 262 Training Loss: 1.7141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 262 Val: 100%|██████████| 19/19 [00:04<00:00,  4.02it/s, val_loss=1.6] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 262 Validation Loss: 1.6028\n",
      "Validation loss (1.6028) did not improve from 1.5996\n",
      "\n",
      "Epoch 263/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 263 Train: 100%|██████████| 75/75 [00:45<00:00,  1.64it/s, loss=1.72]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 263 Training Loss: 1.7155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 263 Val: 100%|██████████| 19/19 [00:04<00:00,  4.03it/s, val_loss=1.6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 263 Validation Loss: 1.5994\n",
      "Validation loss improved from 1.5996 to 1.5994, saving model to models_pytorch/lipnet_checkpoint.pth\n",
      "\n",
      "Epoch 264/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 264 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.71]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 264 Training Loss: 1.7147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 264 Val: 100%|██████████| 19/19 [00:05<00:00,  3.69it/s, val_loss=1.6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 264 Validation Loss: 1.5987\n",
      "Validation loss improved from 1.5994 to 1.5987, saving model to models_pytorch/lipnet_checkpoint.pth\n",
      "\n",
      "Epoch 265/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 265 Train: 100%|██████████| 75/75 [00:45<00:00,  1.64it/s, loss=1.71]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 265 Training Loss: 1.7110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 265 Val: 100%|██████████| 19/19 [00:04<00:00,  3.88it/s, val_loss=1.6] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 265 Validation Loss: 1.6023\n",
      "Validation loss (1.6023) did not improve from 1.5987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Argmax Indices (Example 1): [19, 0, 1, 20, 27, 27, 7, 18, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 20, 27, 27, 27, 27, 27, 27, 27, 27, 27, 19, 9, 5, 0, 0, 27, 27, 27, 0, 14, 1, 15, 14]\n",
      "\n",
      "--- Example Predictions ---\n",
      "Original:     set blue with f four now\n",
      "Filtered Idx: [19, 1, 20, 27, 7, 18, 5, 9, 20, 27, 19, 9, 5, 27, 14, 1, 15, 14]\n",
      "Prediction:   sat greit sie naon\n",
      "--------------------------------------------------\n",
      "Original:     set white in m one again\n",
      "Filtered Idx: [19, 1, 25, 27, 23, 18, 5, 9, 20, 27, 9, 5, 27, 15, 1, 15, 14]\n",
      "Prediction:   say wreit ie oaon\n",
      "--------------------------------------------------\n",
      "--- End Examples ---\n",
      "\n",
      "\n",
      "Epoch 266/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 266 Train: 100%|██████████| 75/75 [00:45<00:00,  1.64it/s, loss=1.71]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 266 Training Loss: 1.7094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 266 Val: 100%|██████████| 19/19 [00:04<00:00,  4.02it/s, val_loss=1.6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 266 Validation Loss: 1.5964\n",
      "Validation loss improved from 1.5987 to 1.5964, saving model to models_pytorch/lipnet_checkpoint.pth\n",
      "\n",
      "Epoch 267/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 267 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.72]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 267 Training Loss: 1.7155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 267 Val: 100%|██████████| 19/19 [00:04<00:00,  3.97it/s, val_loss=1.6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 267 Validation Loss: 1.5958\n",
      "Validation loss improved from 1.5964 to 1.5958, saving model to models_pytorch/lipnet_checkpoint.pth\n",
      "\n",
      "Epoch 268/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 268 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.72]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 268 Training Loss: 1.7165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 268 Val: 100%|██████████| 19/19 [00:04<00:00,  3.99it/s, val_loss=1.59]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 268 Validation Loss: 1.5943\n",
      "Validation loss improved from 1.5958 to 1.5943, saving model to models_pytorch/lipnet_checkpoint.pth\n",
      "\n",
      "Epoch 269/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 269 Train: 100%|██████████| 75/75 [00:45<00:00,  1.64it/s, loss=1.71]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 269 Training Loss: 1.7116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 269 Val: 100%|██████████| 19/19 [00:04<00:00,  4.04it/s, val_loss=1.6] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 269 Validation Loss: 1.5965\n",
      "Validation loss (1.5965) did not improve from 1.5943\n",
      "\n",
      "Epoch 270/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 270 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.72]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 270 Training Loss: 1.7151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 270 Val: 100%|██████████| 19/19 [00:04<00:00,  3.93it/s, val_loss=1.59]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 270 Validation Loss: 1.5932\n",
      "Validation loss improved from 1.5943 to 1.5932, saving model to models_pytorch/lipnet_checkpoint.pth\n",
      "Raw Argmax Indices (Example 1): [19, 0, 1, 20, 27, 27, 7, 18, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 20, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 9, 5, 0, 0, 27, 27, 27, 0, 14, 1, 15, 14]\n",
      "\n",
      "--- Example Predictions ---\n",
      "Original:     set blue with f four now\n",
      "Filtered Idx: [19, 1, 20, 27, 7, 18, 5, 9, 20, 27, 9, 5, 27, 14, 1, 15, 14]\n",
      "Prediction:   sat greit ie naon\n",
      "--------------------------------------------------\n",
      "Original:     set white in m one again\n",
      "Filtered Idx: [19, 1, 25, 27, 23, 18, 5, 9, 20, 27, 9, 5, 27, 7, 1, 15, 14]\n",
      "Prediction:   say wreit ie gaon\n",
      "--------------------------------------------------\n",
      "--- End Examples ---\n",
      "\n",
      "\n",
      "Epoch 271/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 271 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.71]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 271 Training Loss: 1.7113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 271 Val: 100%|██████████| 19/19 [00:04<00:00,  3.96it/s, val_loss=1.6] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 271 Validation Loss: 1.5963\n",
      "Validation loss (1.5963) did not improve from 1.5932\n",
      "\n",
      "Epoch 272/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 272 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.71]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 272 Training Loss: 1.7128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 272 Val: 100%|██████████| 19/19 [00:04<00:00,  3.95it/s, val_loss=1.6] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 272 Validation Loss: 1.6023\n",
      "Validation loss (1.6023) did not improve from 1.5932\n",
      "\n",
      "Epoch 273/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 273 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.71]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 273 Training Loss: 1.7056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 273 Val: 100%|██████████| 19/19 [00:04<00:00,  3.96it/s, val_loss=1.59]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 273 Validation Loss: 1.5851\n",
      "Validation loss improved from 1.5932 to 1.5851, saving model to models_pytorch/lipnet_checkpoint.pth\n",
      "\n",
      "Epoch 274/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 274 Train: 100%|██████████| 75/75 [00:45<00:00,  1.64it/s, loss=1.71]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 274 Training Loss: 1.7105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 274 Val: 100%|██████████| 19/19 [00:04<00:00,  3.98it/s, val_loss=1.59]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 274 Validation Loss: 1.5941\n",
      "Validation loss (1.5941) did not improve from 1.5851\n",
      "\n",
      "Epoch 275/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 275 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.71]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 275 Training Loss: 1.7082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 275 Val: 100%|██████████| 19/19 [00:04<00:00,  3.81it/s, val_loss=1.59]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 275 Validation Loss: 1.5901\n",
      "Validation loss (1.5901) did not improve from 1.5851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Argmax Indices (Example 1): [19, 0, 1, 20, 27, 27, 7, 18, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 20, 27, 27, 27, 27, 27, 27, 27, 27, 27, 19, 9, 5, 0, 0, 27, 27, 27, 0, 14, 1, 15, 14]\n",
      "\n",
      "--- Example Predictions ---\n",
      "Original:     set blue with f four now\n",
      "Filtered Idx: [19, 1, 20, 27, 7, 18, 5, 9, 20, 27, 19, 9, 5, 27, 14, 1, 15, 14]\n",
      "Prediction:   sat greit sie naon\n",
      "--------------------------------------------------\n",
      "Original:     set white in m one again\n",
      "Filtered Idx: [19, 1, 25, 27, 23, 18, 5, 9, 20, 27, 9, 5, 27, 15, 1, 15, 14]\n",
      "Prediction:   say wreit ie oaon\n",
      "--------------------------------------------------\n",
      "--- End Examples ---\n",
      "\n",
      "\n",
      "Epoch 276/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 276 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.71]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 276 Training Loss: 1.7082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 276 Val: 100%|██████████| 19/19 [00:04<00:00,  4.01it/s, val_loss=1.59]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 276 Validation Loss: 1.5866\n",
      "Validation loss (1.5866) did not improve from 1.5851\n",
      "\n",
      "Epoch 277/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 277 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.71]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 277 Training Loss: 1.7095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 277 Val: 100%|██████████| 19/19 [00:04<00:00,  3.94it/s, val_loss=1.6] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 277 Validation Loss: 1.5965\n",
      "Validation loss (1.5965) did not improve from 1.5851\n",
      "\n",
      "Epoch 278/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 278 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.71]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 278 Training Loss: 1.7100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 278 Val: 100%|██████████| 19/19 [00:04<00:00,  3.88it/s, val_loss=1.59]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 278 Validation Loss: 1.5900\n",
      "Validation loss (1.5900) did not improve from 1.5851\n",
      "\n",
      "Epoch 279/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 279 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.71]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 279 Training Loss: 1.7117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 279 Val: 100%|██████████| 19/19 [00:04<00:00,  3.98it/s, val_loss=1.59]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 279 Validation Loss: 1.5857\n",
      "Validation loss (1.5857) did not improve from 1.5851\n",
      "\n",
      "Epoch 280/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 280 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.7] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 280 Training Loss: 1.7042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 280 Val: 100%|██████████| 19/19 [00:04<00:00,  3.95it/s, val_loss=1.58]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 280 Validation Loss: 1.5845\n",
      "Validation loss improved from 1.5851 to 1.5845, saving model to models_pytorch/lipnet_checkpoint.pth\n",
      "Raw Argmax Indices (Example 1): [19, 0, 1, 20, 27, 27, 7, 18, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 20, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 9, 5, 0, 0, 27, 27, 27, 0, 14, 1, 15, 14]\n",
      "\n",
      "--- Example Predictions ---\n",
      "Original:     set blue with f four now\n",
      "Filtered Idx: [19, 1, 20, 27, 7, 18, 5, 9, 20, 27, 9, 5, 27, 14, 1, 15, 14]\n",
      "Prediction:   sat greit ie naon\n",
      "--------------------------------------------------\n",
      "Original:     set white in m one again\n",
      "Filtered Idx: [19, 1, 25, 27, 23, 18, 5, 9, 20, 27, 9, 5, 27, 7, 1, 15, 14]\n",
      "Prediction:   say wreit ie gaon\n",
      "--------------------------------------------------\n",
      "--- End Examples ---\n",
      "\n",
      "\n",
      "Epoch 281/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 281 Train: 100%|██████████| 75/75 [00:45<00:00,  1.64it/s, loss=1.71]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281 Training Loss: 1.7075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 281 Val: 100%|██████████| 19/19 [00:04<00:00,  3.88it/s, val_loss=1.59]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281 Validation Loss: 1.5879\n",
      "Validation loss (1.5879) did not improve from 1.5845\n",
      "\n",
      "Epoch 282/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 282 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.71]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 282 Training Loss: 1.7131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 282 Val: 100%|██████████| 19/19 [00:04<00:00,  3.96it/s, val_loss=1.59]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 282 Validation Loss: 1.5866\n",
      "Validation loss (1.5866) did not improve from 1.5845\n",
      "\n",
      "Epoch 283/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 283 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.7] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 283 Training Loss: 1.7050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 283 Val: 100%|██████████| 19/19 [00:04<00:00,  3.90it/s, val_loss=1.59]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 283 Validation Loss: 1.5870\n",
      "Validation loss (1.5870) did not improve from 1.5845\n",
      "\n",
      "Epoch 284/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 284 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.71]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 284 Training Loss: 1.7062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 284 Val: 100%|██████████| 19/19 [00:04<00:00,  3.99it/s, val_loss=1.58]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 284 Validation Loss: 1.5837\n",
      "Validation loss improved from 1.5845 to 1.5837, saving model to models_pytorch/lipnet_checkpoint.pth\n",
      "\n",
      "Epoch 285/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 285 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.71]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 285 Training Loss: 1.7099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 285 Val: 100%|██████████| 19/19 [00:04<00:00,  3.97it/s, val_loss=1.58]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 285 Validation Loss: 1.5848\n",
      "Validation loss (1.5848) did not improve from 1.5837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Argmax Indices (Example 1): [19, 0, 1, 20, 27, 27, 7, 18, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 20, 27, 27, 27, 27, 27, 27, 27, 27, 27, 19, 9, 5, 0, 0, 27, 27, 27, 0, 14, 1, 15, 14]\n",
      "\n",
      "--- Example Predictions ---\n",
      "Original:     set blue with f four now\n",
      "Filtered Idx: [19, 1, 20, 27, 7, 18, 5, 9, 20, 27, 19, 9, 5, 27, 14, 1, 15, 14]\n",
      "Prediction:   sat greit sie naon\n",
      "--------------------------------------------------\n",
      "Original:     set white in m one again\n",
      "Filtered Idx: [19, 1, 25, 27, 23, 18, 5, 9, 20, 27, 9, 5, 27, 7, 1, 15, 14]\n",
      "Prediction:   say wreit ie gaon\n",
      "--------------------------------------------------\n",
      "--- End Examples ---\n",
      "\n",
      "\n",
      "Epoch 286/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 286 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.71]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286 Training Loss: 1.7089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 286 Val: 100%|██████████| 19/19 [00:04<00:00,  3.99it/s, val_loss=1.58]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286 Validation Loss: 1.5833\n",
      "Validation loss improved from 1.5837 to 1.5833, saving model to models_pytorch/lipnet_checkpoint.pth\n",
      "\n",
      "Epoch 287/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 287 Train: 100%|██████████| 75/75 [00:45<00:00,  1.64it/s, loss=1.71]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 287 Training Loss: 1.7077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 287 Val: 100%|██████████| 19/19 [00:04<00:00,  3.97it/s, val_loss=1.58]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 287 Validation Loss: 1.5845\n",
      "Validation loss (1.5845) did not improve from 1.5833\n",
      "\n",
      "Epoch 288/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 288 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.71]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 288 Training Loss: 1.7078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 288 Val: 100%|██████████| 19/19 [00:04<00:00,  3.96it/s, val_loss=1.59]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 288 Validation Loss: 1.5869\n",
      "Validation loss (1.5869) did not improve from 1.5833\n",
      "\n",
      "Epoch 289/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 289 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.71]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 289 Training Loss: 1.7059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 289 Val: 100%|██████████| 19/19 [00:04<00:00,  3.95it/s, val_loss=1.59]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 289 Validation Loss: 1.5853\n",
      "Validation loss (1.5853) did not improve from 1.5833\n",
      "\n",
      "Epoch 290/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 290 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.71]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 290 Training Loss: 1.7071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 290 Val: 100%|██████████| 19/19 [00:04<00:00,  4.02it/s, val_loss=1.58]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 290 Validation Loss: 1.5848\n",
      "Validation loss (1.5848) did not improve from 1.5833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Argmax Indices (Example 1): [19, 0, 1, 20, 27, 27, 7, 18, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 20, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 9, 5, 0, 0, 27, 27, 27, 0, 14, 1, 15, 14]\n",
      "\n",
      "--- Example Predictions ---\n",
      "Original:     set blue with f four now\n",
      "Filtered Idx: [19, 1, 20, 27, 7, 18, 5, 9, 20, 27, 9, 5, 27, 14, 1, 15, 14]\n",
      "Prediction:   sat greit ie naon\n",
      "--------------------------------------------------\n",
      "Original:     set white in m one again\n",
      "Filtered Idx: [19, 1, 25, 27, 23, 18, 5, 9, 20, 27, 9, 5, 27, 7, 1, 15, 14]\n",
      "Prediction:   say wreit ie gaon\n",
      "--------------------------------------------------\n",
      "--- End Examples ---\n",
      "\n",
      "\n",
      "Epoch 291/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 291 Train: 100%|██████████| 75/75 [00:45<00:00,  1.64it/s, loss=1.71]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 291 Training Loss: 1.7054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 291 Val: 100%|██████████| 19/19 [00:04<00:00,  4.00it/s, val_loss=1.58]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 291 Validation Loss: 1.5835\n",
      "Validation loss (1.5835) did not improve from 1.5833\n",
      "\n",
      "Epoch 292/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 292 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.7] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 292 Training Loss: 1.7049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 292 Val: 100%|██████████| 19/19 [00:04<00:00,  4.04it/s, val_loss=1.59]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 292 Validation Loss: 1.5858\n",
      "Validation loss (1.5858) did not improve from 1.5833\n",
      "\n",
      "Epoch 293/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 293 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.71]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 293 Training Loss: 1.7093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 293 Val: 100%|██████████| 19/19 [00:04<00:00,  3.87it/s, val_loss=1.59]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 293 Validation Loss: 1.5850\n",
      "Validation loss (1.5850) did not improve from 1.5833\n",
      "\n",
      "Epoch 294/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 294 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.71]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 294 Training Loss: 1.7065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 294 Val: 100%|██████████| 19/19 [00:04<00:00,  4.05it/s, val_loss=1.59]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 294 Validation Loss: 1.5853\n",
      "Validation loss (1.5853) did not improve from 1.5833\n",
      "\n",
      "Epoch 295/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 295 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.71]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 295 Training Loss: 1.7078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 295 Val: 100%|██████████| 19/19 [00:04<00:00,  3.84it/s, val_loss=1.59]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 295 Validation Loss: 1.5860\n",
      "Validation loss (1.5860) did not improve from 1.5833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Argmax Indices (Example 1): [19, 0, 1, 20, 27, 27, 7, 18, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 20, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 9, 5, 0, 0, 27, 27, 27, 0, 14, 1, 15, 14]\n",
      "\n",
      "--- Example Predictions ---\n",
      "Original:     set blue with f four now\n",
      "Filtered Idx: [19, 1, 20, 27, 7, 18, 5, 9, 20, 27, 9, 5, 27, 14, 1, 15, 14]\n",
      "Prediction:   sat greit ie naon\n",
      "--------------------------------------------------\n",
      "Original:     set white in m one again\n",
      "Filtered Idx: [19, 1, 25, 27, 23, 18, 5, 9, 20, 27, 19, 9, 5, 27, 7, 1, 15, 14]\n",
      "Prediction:   say wreit sie gaon\n",
      "--------------------------------------------------\n",
      "--- End Examples ---\n",
      "\n",
      "\n",
      "Epoch 296/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 296 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.71]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 296 Training Loss: 1.7055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 296 Val: 100%|██████████| 19/19 [00:04<00:00,  3.80it/s, val_loss=1.59]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 296 Validation Loss: 1.5851\n",
      "Validation loss (1.5851) did not improve from 1.5833\n",
      "\n",
      "Epoch 297/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 297 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.7] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 297 Training Loss: 1.7044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 297 Val: 100%|██████████| 19/19 [00:05<00:00,  3.78it/s, val_loss=1.58]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 297 Validation Loss: 1.5845\n",
      "Validation loss (1.5845) did not improve from 1.5833\n",
      "\n",
      "Epoch 298/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 298 Train: 100%|██████████| 75/75 [00:45<00:00,  1.65it/s, loss=1.7] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 298 Training Loss: 1.7013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 298 Val: 100%|██████████| 19/19 [00:05<00:00,  3.59it/s, val_loss=1.58]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 298 Validation Loss: 1.5848\n",
      "Validation loss (1.5848) did not improve from 1.5833\n",
      "\n",
      "Epoch 299/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 299 Train:  40%|████      | 30/75 [00:19<00:29,  1.53it/s, loss=1.71]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 66\u001b[39m\n\u001b[32m     64\u001b[39m loss.backward()\n\u001b[32m     65\u001b[39m torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=\u001b[32m1.0\u001b[39m) \u001b[38;5;66;03m# Clip gradients\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     68\u001b[39m running_loss += loss.item()\n\u001b[32m     69\u001b[39m train_pbar.set_postfix({\u001b[33m'\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m'\u001b[39m: running_loss / (i + \u001b[32m1\u001b[39m)})\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/torch/optim/optimizer.py:493\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    488\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    489\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    490\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    491\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m493\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    496\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/torch/optim/optimizer.py:91\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     89\u001b[39m     torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.defaults[\u001b[33m\"\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     90\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     93\u001b[39m     torch._dynamo.graph_break()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/torch/optim/adam.py:244\u001b[39m, in \u001b[36mAdam.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    232\u001b[39m     beta1, beta2 = group[\u001b[33m\"\u001b[39m\u001b[33mbetas\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    234\u001b[39m     has_complex = \u001b[38;5;28mself\u001b[39m._init_group(\n\u001b[32m    235\u001b[39m         group,\n\u001b[32m    236\u001b[39m         params_with_grad,\n\u001b[32m   (...)\u001b[39m\u001b[32m    241\u001b[39m         state_steps,\n\u001b[32m    242\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m244\u001b[39m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    246\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mamsgrad\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meps\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaximize\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mforeach\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcapturable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdifferentiable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfused\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgrad_scale\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfound_inf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/torch/optim/optimizer.py:154\u001b[39m, in \u001b[36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    152\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(*args, **kwargs)\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/torch/optim/adam.py:876\u001b[39m, in \u001b[36madam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[39m\n\u001b[32m    873\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    874\u001b[39m     func = _single_tensor_adam\n\u001b[32m--> \u001b[39m\u001b[32m876\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    887\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    890\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    891\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    892\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    893\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    894\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    895\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/torch/optim/adam.py:685\u001b[39m, in \u001b[36m_multi_tensor_adam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[39m\n\u001b[32m    682\u001b[39m     torch._foreach_addcdiv_(device_params, device_exp_avgs, exp_avg_sq_sqrt)\n\u001b[32m    683\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    684\u001b[39m     bias_correction1 = [\n\u001b[32m--> \u001b[39m\u001b[32m685\u001b[39m         \u001b[32m1\u001b[39m - beta1 ** \u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m device_state_steps\n\u001b[32m    686\u001b[39m     ]\n\u001b[32m    687\u001b[39m     bias_correction2 = [\n\u001b[32m    688\u001b[39m         \u001b[32m1\u001b[39m - beta2 ** _get_value(step) \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m device_state_steps\n\u001b[32m    689\u001b[39m     ]\n\u001b[32m    691\u001b[39m     step_size = _stack_if_compiling([(lr / bc) * -\u001b[32m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m bc \u001b[38;5;129;01min\u001b[39;00m bias_correction1])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/torch/optim/optimizer.py:106\u001b[39m, in \u001b[36m_get_value\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m    104\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[32m    105\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, torch.Tensor) \u001b[38;5;28;01melse\u001b[39;00m x\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# --- Training Loop ---\n",
    "EPOCHS = 300\n",
    "best_val_loss = float('inf')\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# Load checkpoint if exists\n",
    "start_epoch = 0\n",
    "if os.path.exists(checkpoint_path):\n",
    "    print(f\"Loading checkpoint from {checkpoint_path}\")\n",
    "    try:\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=DEVICE)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        best_val_loss = checkpoint['loss']\n",
    "        print(f\"Resuming training from epoch {start_epoch}, Best loss: {best_val_loss:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading checkpoint: {e}. Starting from scratch.\")\n",
    "        start_epoch = 0\n",
    "        best_val_loss = float('inf')\n",
    "\n",
    "\n",
    "print(\"\\nStarting Training...\")\n",
    "num_train_batches = len(train_loader)\n",
    "num_test_batches = len(test_loader)\n",
    "print(f\"Training batches per epoch: {num_train_batches}\")\n",
    "print(f\"Validation batches per epoch: {num_test_batches}\")\n",
    "\n",
    "\n",
    "for epoch in range(start_epoch, EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    train_pbar = tqdm(enumerate(train_loader), total=num_train_batches, desc=f\"Epoch {epoch+1} Train\")\n",
    "\n",
    "    for i, batch_data in train_pbar:\n",
    "        frames_batch, labels_padded, input_lengths, label_lengths = batch_data\n",
    "\n",
    "        # Move data to device\n",
    "        frames_batch = frames_batch.to(DEVICE)\n",
    "        labels_padded = labels_padded.to(DEVICE)\n",
    "        input_lengths = input_lengths.to(DEVICE)\n",
    "        label_lengths = label_lengths.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        log_probs = model(frames_batch)\n",
    "\n",
    "        T = log_probs.size(0)\n",
    "        input_lengths = torch.clamp(input_lengths, max=T)\n",
    "\n",
    "        loss = ctc_loss(log_probs, labels_padded.cpu(), input_lengths.cpu(), label_lengths.cpu())\n",
    "\n",
    "        # Check for NaN/inf loss\n",
    "        if torch.isnan(loss) or torch.isinf(loss):\n",
    "             print(f\"Warning: NaN or Inf loss detected at batch {i}. Skipping batch.\")\n",
    "             continue # Skip gradient update for this batch\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0) # Clip gradients\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        train_pbar.set_postfix({'loss': running_loss / (i + 1)})\n",
    "\n",
    "    avg_train_loss = running_loss / num_train_batches\n",
    "    train_losses.append(avg_train_loss)\n",
    "    print(f\"Epoch {epoch+1} Training Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # --- Validation ---\n",
    "    model.eval()\n",
    "    running_val_loss = 0.0\n",
    "    val_pbar = tqdm(enumerate(test_loader), total=num_test_batches, desc=f\"Epoch {epoch+1} Val\")\n",
    "    with torch.no_grad():\n",
    "        for i, batch_data in val_pbar:\n",
    "            frames_batch, labels_padded, input_lengths, label_lengths = batch_data\n",
    "            frames_batch = frames_batch.to(DEVICE)\n",
    "            labels_padded = labels_padded.to(DEVICE)\n",
    "            input_lengths = input_lengths.to(DEVICE)\n",
    "            label_lengths = label_lengths.to(DEVICE)\n",
    "\n",
    "            log_probs = model(frames_batch)\n",
    "            T = log_probs.size(0)\n",
    "            input_lengths = torch.clamp(input_lengths, max=T)\n",
    "\n",
    "            loss = ctc_loss(log_probs, labels_padded.cpu(), input_lengths.cpu(), label_lengths.cpu())\n",
    "\n",
    "            if not (torch.isnan(loss) or torch.isinf(loss)):\n",
    "                running_val_loss += loss.item()\n",
    "            val_pbar.set_postfix({'val_loss': running_val_loss / (i + 1)})\n",
    "\n",
    "    avg_val_loss = running_val_loss / num_test_batches\n",
    "    val_losses.append(avg_val_loss)\n",
    "    print(f\"Epoch {epoch+1} Validation Loss: {avg_val_loss:.4f}\")\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "    # --- Save Checkpoint ---\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        print(f\"Validation loss improved from {best_val_loss:.4f} to {avg_val_loss:.4f}, saving model to {checkpoint_path}\")\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': avg_val_loss,\n",
    "        }, checkpoint_path)\n",
    "        best_val_loss = avg_val_loss\n",
    "    else:\n",
    "        print(f\"Validation loss ({avg_val_loss:.4f}) did not improve from {best_val_loss:.4f}\")\n",
    "\n",
    "    # --- Show Examples (e.g., every 5 epochs) ---\n",
    "    if (epoch + 1) % 5 == 0 or epoch == EPOCHS - 1:\n",
    "         produce_example(model, test_loader, num_to_char_dict)\n",
    "\n",
    "print(\"\\nTraining Finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "033fbf86-b8f4-496e-a34d-d2efc7ebd1a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running Final Test Examples ---\n",
      "Loading best weights from models_pytorch/lipnet_checkpoint.pth for final test...\n",
      "Best weights loaded successfully.\n",
      "\n",
      "--- Example Predictions ---\n",
      "Original:     place green with r seven again\n",
      "Filtered Idx: [14]\n",
      "Prediction:   n\n",
      "--------------------------------------------------\n",
      "Original:     bin green with u nine again\n",
      "Filtered Idx: [14]\n",
      "Prediction:   n\n",
      "--------------------------------------------------\n",
      "--- End Examples ---\n",
      "\n",
      "--- Final Testing Finished ---\n"
     ]
    }
   ],
   "source": [
    "# --- Plotting Training/Validation Loss ---\n",
    "plt.figure(figsize=(8, 3))\n",
    "plt.plot(train_losses, color='red', label=\"Training Loss\")\n",
    "plt.plot(val_losses, color='green', label=\"Validation Loss\")\n",
    "plt.title(\"Training/Validation Loss vs Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"loss_curve_pytorch.png\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n--- Running Final Test Examples ---\")\n",
    "if os.path.exists(checkpoint_path):\n",
    "    print(f\"Loading best weights from {checkpoint_path} for final test...\")\n",
    "    try:\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=DEVICE)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        print(\"Best weights loaded successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading best weights: {e}\")\n",
    "else:\n",
    "    print(\"No checkpoint found for final testing.\")\n",
    "\n",
    "produce_example(model, test_loader, num_to_char_dict) # Show examples with best model\n",
    "print(\"--- Final Testing Finished ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5616408-1252-47a9-9906-78fc0e143804",
   "metadata": {},
   "source": [
    "# Testing on Unseen Speakers: s31, s32, s33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05c503c4-0743-4006-83bf-6ebc33bbfe77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading trained model...\n",
      "Model loaded successfully from epoch 285\n",
      "\n",
      "Finding all processed .npy files...\n",
      "Found 3000 total .npy files.\n",
      "\n",
      "Selected 20 files for testing.\n",
      "\n",
      "--- Running Inference on Selected Samples ---\n",
      "\n",
      "--- Sample 1/20 ---\n",
      "File: ./GRIDCorpus/processed_mouth_data/s33_processed/srwz2n_mouth.npy\n",
      "Original:     set red with z sp two now\n",
      "Prediction:   sat breit ie naon\n",
      "\n",
      "--- Sample 2/20 ---\n",
      "File: ./GRIDCorpus/processed_mouth_data/s32_processed/srbe7n_mouth.npy\n",
      "Original:     set red by e seven now\n",
      "Prediction:   say wreit ie naon\n",
      "\n",
      "--- Sample 3/20 ---\n",
      "File: ./GRIDCorpus/processed_mouth_data/s31_processed/prif8p_mouth.npy\n",
      "Original:     place red in f eight please\n",
      "Prediction:   sate breit ie eaon\n",
      "\n",
      "--- Sample 4/20 ---\n",
      "File: ./GRIDCorpus/processed_mouth_data/s32_processed/sriq8s_mouth.npy\n",
      "Original:     set red in q eight soon\n",
      "Prediction:   say greit ie naon\n",
      "\n",
      "--- Sample 5/20 ---\n",
      "File: ./GRIDCorpus/processed_mouth_data/s32_processed/pwaa4a_mouth.npy\n",
      "Original:     place white at a four again\n",
      "Prediction:   say breit ie gaon\n",
      "\n",
      "--- Sample 6/20 ---\n",
      "File: ./GRIDCorpus/processed_mouth_data/s31_processed/bwip9s_mouth.npy\n",
      "Original:     bin white in p nine soon\n",
      "Prediction:   bay wreit ie naon\n",
      "\n",
      "--- Sample 7/20 ---\n",
      "File: ./GRIDCorpus/processed_mouth_data/s32_processed/lwwjzs_mouth.npy\n",
      "Original:     lay white with j zero soon\n",
      "Prediction:   say wreit ie naon\n",
      "\n",
      "--- Sample 8/20 ---\n",
      "File: ./GRIDCorpus/processed_mouth_data/s32_processed/pwat3n_mouth.npy\n",
      "Original:     place white at t three now\n",
      "Prediction:   say greit ie naon\n",
      "\n",
      "--- Sample 9/20 ---\n",
      "File: ./GRIDCorpus/processed_mouth_data/s32_processed/bgaq9p_mouth.npy\n",
      "Original:     bin green at q nine please\n",
      "Prediction:   say greit ie naon\n",
      "\n",
      "--- Sample 10/20 ---\n",
      "File: ./GRIDCorpus/processed_mouth_data/s32_processed/bbivzs_mouth.npy\n",
      "Original:     bin blue in v zero soon\n",
      "Prediction:   sat greit ie naon\n",
      "\n",
      "--- Sample 11/20 ---\n",
      "File: ./GRIDCorpus/processed_mouth_data/s33_processed/lrah5s_mouth.npy\n",
      "Original:     lay red at h five soon\n",
      "Prediction:   sat greit ie naon\n",
      "\n",
      "--- Sample 12/20 ---\n",
      "File: ./GRIDCorpus/processed_mouth_data/s31_processed/pwbt9s_mouth.npy\n",
      "Original:     place white by t nine soon\n",
      "Prediction:   san wreit ie naon\n",
      "\n",
      "--- Sample 13/20 ---\n",
      "File: ./GRIDCorpus/processed_mouth_data/s33_processed/lwio3a_mouth.npy\n",
      "Original:     lay white in o three again\n",
      "Prediction:   say breit ie oaon\n",
      "\n",
      "--- Sample 14/20 ---\n",
      "File: ./GRIDCorpus/processed_mouth_data/s33_processed/bwaqzn_mouth.npy\n",
      "Original:     bin white at q zero now\n",
      "Prediction:   bice breit ie non\n",
      "\n",
      "--- Sample 15/20 ---\n",
      "File: ./GRIDCorpus/processed_mouth_data/s32_processed/pgbu4s_mouth.npy\n",
      "Original:     place green by u four soon\n",
      "Prediction:   sat breit ie non\n",
      "\n",
      "--- Sample 16/20 ---\n",
      "File: ./GRIDCorpus/processed_mouth_data/s32_processed/lbat8s_mouth.npy\n",
      "Original:     lay blue at t eight soon\n",
      "Prediction:   say greit ie non\n",
      "\n",
      "--- Sample 17/20 ---\n",
      "File: ./GRIDCorpus/processed_mouth_data/s33_processed/bbbc7a_mouth.npy\n",
      "Original:     bin blue by c seven again\n",
      "Prediction:   bac breit ie non\n",
      "\n",
      "--- Sample 18/20 ---\n",
      "File: ./GRIDCorpus/processed_mouth_data/s33_processed/lwiu7a_mouth.npy\n",
      "Original:     lay white in u seven again\n",
      "Prediction:   bat breit ie naon\n",
      "\n",
      "--- Sample 19/20 ---\n",
      "File: ./GRIDCorpus/processed_mouth_data/s31_processed/pbil4n_mouth.npy\n",
      "Original:     place blue in l four now\n",
      "Prediction:   bat breit ie eaon\n",
      "\n",
      "--- Sample 20/20 ---\n",
      "File: ./GRIDCorpus/processed_mouth_data/s33_processed/sbiqzn_mouth.npy\n",
      "Original:     set blue in q zero now\n",
      "Prediction:   bat breit ie oaon\n",
      "\n",
      "--- Testing Summary ---\n",
      "Successfully processed: 20/20\n",
      "Correct Predictions: 0/20\n",
      "Accuracy on processed samples: 0.00%\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "def get_align_path(npy_path):\n",
    "    parts = npy_path.split(os.path.sep)\n",
    "    npy_filename = parts[-1]\n",
    "    speaker_processed_dir = parts[-2] \n",
    "    base_name = os.path.splitext(npy_filename)[0]\n",
    "    if base_name.endswith('_mouth'):\n",
    "         base_name = base_name[:-6] \n",
    "    align_dir = os.path.join(\"./GRIDCorpus/data\", speaker_processed_dir, 'align')\n",
    "    return os.path.join(align_dir, f'{base_name}.align')\n",
    "def load_alignments(align_file: str) -> Optional[List[str]]:\n",
    "    alignments_chars = []\n",
    "    try:\n",
    "        with open(align_file, 'r') as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split();\n",
    "                if len(parts) != 3: continue\n",
    "                _, _, token = parts\n",
    "                if token != 'sil': alignments_chars.extend(list(token.lower() + ' '))\n",
    "        return alignments_chars[:-1] if alignments_chars else []\n",
    "    except FileNotFoundError: return None\n",
    "    except Exception as e: print(f\"Error loading {align_file}: {e}\"); return None\n",
    "def load_and_normalize_npy(npy_path: str) -> Optional[torch.Tensor]:\n",
    "    try:\n",
    "        frames_uint8 = np.load(npy_path) \n",
    "        current_frame_count = frames_uint8.shape[0]\n",
    "        if current_frame_count != FRAME_COUNT:\n",
    "            if current_frame_count > FRAME_COUNT:\n",
    "                frames_uint8 = frames_uint8[:FRAME_COUNT, ...]\n",
    "            else:\n",
    "                pad_width = ((0, FRAME_COUNT - current_frame_count), (0, 0), (0, 0), (0, 0))\n",
    "                frames_uint8 = np.pad(frames_uint8, pad_width, mode='constant', constant_values=0)\n",
    "        frames_float = frames_uint8.astype(np.float32) / 255.0\n",
    "        frames_rgb = frames_float[..., ::-1]\n",
    "        frames_normalized = (frames_rgb - NORM_MEAN) / NORM_STD\n",
    "        frames_tensor = torch.tensor(frames_normalized, dtype=torch.float32)\n",
    "        if frames_tensor.shape != (FRAME_COUNT, FRAME_HEIGHT, FRAME_WIDTH, FRAME_CHANNELS):\n",
    "            print(f\"Warning: Final tensor shape is incorrect for {npy_path}: {frames_tensor.shape}\")\n",
    "            return None\n",
    "        return frames_tensor \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: Npy file not found {npy_path}.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading/processing npy {npy_path}: {e}\")\n",
    "        return None\n",
    "def greedy_decoder(log_probs, input_lengths):\n",
    "    decoded_sequences = []\n",
    "    for i in range(log_probs.size(1)):\n",
    "        sample_log_probs = log_probs[:input_lengths[i], i, :]\n",
    "        best_path = torch.argmax(sample_log_probs, dim=1)\n",
    "        decoded = []\n",
    "        last_char = -1\n",
    "        for char_idx in best_path:\n",
    "            idx = char_idx.item()\n",
    "            if idx != last_char and idx != CTC_BLANK_INDEX:\n",
    "                decoded.append(idx)\n",
    "            if idx != CTC_BLANK_INDEX:\n",
    "                last_char = idx\n",
    "        decoded_sequences.append(decoded)\n",
    "    return decoded_sequences\n",
    "class LipNet(nn.Module):\n",
    "    def __init__(self, num_classes, dropout_p=DROPOUT_P):\n",
    "        super(LipNet, self).__init__()\n",
    "        self.num_classes = num_classes \n",
    "        self.dropout_p = dropout_p\n",
    "        self.conv1 = nn.Conv3d(FRAME_CHANNELS, 32, kernel_size=(3, 5, 5), stride=(1, 2, 2), padding=(1, 2, 2))\n",
    "        self.bn1 = nn.BatchNorm3d(32)\n",
    "        self.pool1 = nn.MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2))\n",
    "        self.drop1 = nn.Dropout3d(dropout_p)\n",
    "        self.conv2 = nn.Conv3d(32, 64, kernel_size=(3, 5, 5), stride=(1, 1, 1), padding=(1, 2, 2))\n",
    "        self.bn2 = nn.BatchNorm3d(64)\n",
    "        self.pool2 = nn.MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2))\n",
    "        self.drop2 = nn.Dropout3d(dropout_p)\n",
    "        self.conv3 = nn.Conv3d(64, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
    "        self.bn3 = nn.BatchNorm3d(96)\n",
    "        self.pool3 = nn.MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2))\n",
    "        self.drop3 = nn.Dropout3d(dropout_p)\n",
    "        self.rnn_input_size = 96 * 3 * 6\n",
    "        self.gru1 = nn.GRU(self.rnn_input_size, 256, bidirectional=True, batch_first=True)\n",
    "        self.drop_gru1 = nn.Dropout(dropout_p)\n",
    "        self.gru2 = nn.GRU(256 * 2, 256, bidirectional=True, batch_first=True)\n",
    "        self.drop_gru2 = nn.Dropout(dropout_p)\n",
    "        self.fc = nn.Linear(256 * 2, self.num_classes)\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 4, 1, 2, 3).contiguous()\n",
    "        x = self.conv1(x); x = self.bn1(x); x = F.relu(x); x = self.pool1(x); x = self.drop1(x)\n",
    "        x = self.conv2(x); x = self.bn2(x); x = F.relu(x); x = self.pool2(x); x = self.drop2(x)\n",
    "        x = self.conv3(x); x = self.bn3(x); x = F.relu(x); x = self.pool3(x); x = self.drop3(x)\n",
    "        N, C, T, H, W = x.size(); x = x.permute(0, 2, 1, 3, 4).contiguous(); x = x.view(N, T, -1)\n",
    "        x, _ = self.gru1(x); x = self.drop_gru1(x)\n",
    "        x, _ = self.gru2(x); x = self.drop_gru2(x)\n",
    "        x = self.fc(x)\n",
    "        x = x.permute(1, 0, 2).contiguous()\n",
    "        log_probs = F.log_softmax(x, dim=2)\n",
    "        return log_probs\n",
    "K = 20 \n",
    "CHECKPOINT_PATH = './models_pytorch/lipnet_checkpoint.pth' \n",
    "ALL_SPEAKER_IDS_NUM = [\"s31_processed\", \"s32_processed\", \"s33_processed\"]\n",
    "print(\"Loading trained model...\")\n",
    "model = LipNet(num_classes=VOCAB_SIZE + 1).to(DEVICE)\n",
    "if not os.path.exists(CHECKPOINT_PATH):\n",
    "    print(f\"Error: Checkpoint file not found at {CHECKPOINT_PATH}\")\n",
    "    exit()\n",
    "try:\n",
    "    checkpoint = torch.load(CHECKPOINT_PATH, map_location=DEVICE)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval() \n",
    "    print(f\"Model loaded successfully from epoch {checkpoint.get('epoch', 'N/A')}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model state_dict: {e}\")\n",
    "    exit()\n",
    "print(\"\\nFinding all processed .npy files...\")\n",
    "all_npy_files = []\n",
    "for speaker_id_num in ALL_SPEAKER_IDS_NUM:\n",
    "    speaker_processed_folder = f\"{speaker_id_num}\"\n",
    "    speaker_path_pattern = os.path.join(BASE_PROCESSED_PATH, speaker_processed_folder, '*.npy')\n",
    "    files = glob.glob(speaker_path_pattern)\n",
    "    if not files:\n",
    "        print(f\"Warning: No .npy files found for speaker {speaker_id_num} in {os.path.join(BASE_PROCESSED_PATH, speaker_processed_folder)}\")\n",
    "    all_npy_files.extend(files)\n",
    "if not all_npy_files:\n",
    "    print(f\"Error: No .npy files found in subdirectories like {os.path.join(BASE_PROCESSED_PATH, 's*_processed/')}. Ensure preprocessing was done and BASE_PROCESSED_PATH is correct.\")\n",
    "    exit()\n",
    "print(f\"Found {len(all_npy_files)} total .npy files.\")\n",
    "random.shuffle(all_npy_files)\n",
    "selected_files = all_npy_files[:K]\n",
    "print(f\"\\nSelected {len(selected_files)} files for testing.\")\n",
    "print(\"\\n--- Running Inference on Selected Samples ---\")\n",
    "correct_predictions = 0\n",
    "processed_count = 0\n",
    "with torch.no_grad():\n",
    "    for i, npy_path in enumerate(selected_files):\n",
    "        print(f\"\\n--- Sample {i+1}/{K} ---\")\n",
    "        print(f\"File: {npy_path}\")\n",
    "        frames_tensor = load_and_normalize_npy(npy_path)\n",
    "        if frames_tensor is None:\n",
    "            print(\"  Skipping due to loading/preprocessing error.\")\n",
    "            continue\n",
    "        input_batch = frames_tensor.unsqueeze(0).to(DEVICE) \n",
    "        align_path = get_align_path(npy_path)\n",
    "        alignments_list = load_alignments(align_path)\n",
    "        if alignments_list is None:\n",
    "            print(f\"  Skipping due to missing alignment file: {align_path}\")\n",
    "            continue\n",
    "        original_text = \"\".join(alignments_list)\n",
    "        print(f\"Original:     {original_text}\")\n",
    "        log_probs = model(input_batch) \n",
    "        input_lengths = torch.tensor([FRAME_COUNT], dtype=torch.long).cpu()\n",
    "        decoded_indices_list = greedy_decoder(log_probs.cpu(), input_lengths)\n",
    "        prediction_indices = decoded_indices_list[0]\n",
    "        prediction_text = \"\".join([num_to_char_dict.get(idx, '?') for idx in prediction_indices])\n",
    "        print(f\"Prediction:   {prediction_text}\")\n",
    "        processed_count += 1\n",
    "        if original_text == prediction_text:\n",
    "             correct_predictions += 1\n",
    "print(\"\\n--- Testing Summary ---\")\n",
    "if processed_count > 0:\n",
    "    accuracy = (correct_predictions / processed_count) * 100\n",
    "    print(f\"Successfully processed: {processed_count}/{len(selected_files)}\")\n",
    "    print(f\"Correct Predictions: {correct_predictions}/{processed_count}\")\n",
    "    print(f\"Accuracy on processed samples: {accuracy:.2f}%\")\n",
    "else:\n",
    "    print(\"No samples were successfully processed for testing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a0f99a-4de8-4397-86bf-b3a3b642777c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
